import os
import sys
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm  # å¯¼å…¥å­—ä½“ç®¡ç†æ¨¡å—
from torch.utils.data import Dataset, DataLoader
import gzip
import numpy as np
import shutil

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œè§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
plt.rcParams['font.sans-serif'] = ['SimHei']  # ä½¿ç”¨é»‘ä½“æ˜¾ç¤ºä¸­æ–‡
plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·'-'æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜

# 1. å¢å¼ºçš„æ•°æ®é›†ä¸‹è½½å‡½æ•°
# =====================================================================
class CustomMNIST(Dataset):
    """è‡ªå®šä¹‰MNISTæ•°æ®é›†ç±»ï¼ŒåŒ…å«æ›´å¥å£®çš„ä¸‹è½½å’ŒåŠ è½½æœºåˆ¶"""
    
    # å¤‡ç”¨é•œåƒURL
    RESOURCES = [
        ('https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz', 'f68b3c2dcbeaaa9fbdd348bbdeb94873'),
        ('https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz', 'd53e105ee54ea40749a09fcbcd1e9432'),
        ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz', '9fb629c4188051af3d5e6f500435b918'),
        ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz', 'bfd4c38d0a60200e93c8bded2a94ff71')
    ]
    
    def __init__(self, root, train=True, transform=None, download=False):
        self.root = root
        self.transform = transform
        self.train = train
        
        if download:
            self.download()
            
        self.data, self.targets = self.load_data()
        
    def download(self):
        """å¦‚æœæœ¬åœ°ä¸å­˜åœ¨åˆ™ä¸‹è½½æ•°æ®é›†"""
        if os.path.exists(os.path.join(self.root, 'processed', 'training.pt')):
            print("MNISTæ•°æ®é›†å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
            return
            
        print("ä¸‹è½½MNISTæ•°æ®é›†...")
        os.makedirs(self.root, exist_ok=True)
        
        for url, md5 in self.RESOURCES:
            filename = url.rpartition('/')[2]
            dest_path = os.path.join(self.root, filename)
            
            # ä¸‹è½½æ–‡ä»¶
            if not os.path.exists(dest_path):
                print(f"æ­£åœ¨ä¸‹è½½: {url}")
                torch.hub.download_url_to_file(url, dest_path)
                
            # è§£å‹æ–‡ä»¶
            extracted_path = dest_path[:-3]  # å»æ‰.gzæ‰©å±•å
            if not os.path.exists(extracted_path):
                print(f"æ­£åœ¨è§£å‹: {filename}")
                with gzip.open(dest_path, 'rb') as f_in:
                    with open(extracted_path, 'wb') as f_out:
                        shutil.copyfileobj(f_in, f_out)
                        
            print(f"å·²ä¸‹è½½å¹¶è§£å‹: {filename}")
            
    def load_data(self):
        """ä»æœ¬åœ°æ–‡ä»¶åŠ è½½æ•°æ®"""
        if self.train:
            images_path = os.path.join(self.root, 'train-images-idx3-ubyte')
            labels_path = os.path.join(self.root, 'train-labels-idx1-ubyte')
        else:
            images_path = os.path.join(self.root, 't10k-images-idx3-ubyte')
            labels_path = os.path.join(self.root, 't10k-labels-idx1-ubyte')
            
        with open(images_path, 'rb') as f:
            # è·³è¿‡å‰16å­—èŠ‚çš„å¤´éƒ¨ä¿¡æ¯
            images = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1, 28, 28)
            
        with open(labels_path, 'rb') as f:
            # è·³è¿‡å‰8å­—èŠ‚çš„å¤´éƒ¨ä¿¡æ¯
            labels = np.frombuffer(f.read(), np.uint8, offset=8)
            
        return torch.from_numpy(images).float(), torch.from_numpy(labels).long()
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        img, target = self.data[idx], int(self.targets[idx])
        
        # åº”ç”¨è½¬æ¢
        if self.transform:
            img = self.transform(img)
            
        return img, target

# 2. å›¾åƒé¢„å¤„ç†å’Œæ•°æ®åŠ è½½
# =====================================================================
# å®šä¹‰å›¾åƒé¢„å¤„ç†ç®¡é“
transform = transforms.Compose([
    transforms.ToPILImage(),         # å°†numpyæ•°ç»„è½¬æ¢ä¸ºPILå›¾åƒ
    transforms.ToTensor(),            # å°†å›¾åƒè½¬æ¢ä¸ºPyTorchå¼ é‡ (0-255çš„åƒç´ å€¼å˜ä¸º0-1)
    transforms.Normalize((0.1307,), (0.3081,))  # MNISTçš„å‡å€¼å’Œæ ‡å‡†å·®
])

# åˆ›å»ºæ•°æ®ç›®å½•ï¼ˆå½“å‰ç›®å½•ä¸‹ï¼‰
data_dir = './mnist_data'
os.makedirs(data_dir, exist_ok=True)

# åŠ è½½è®­ç»ƒæ•°æ®
train_data = CustomMNIST(
    root=data_dir,
    train=True,
    transform=transform,
    download=True
)

# åŠ è½½æµ‹è¯•æ•°æ®
test_data = CustomMNIST(
    root=data_dir,
    train=False,
    transform=transform
)

# åˆ›å»ºæ•°æ®åŠ è½½å™¨
train_loader = DataLoader(
    train_data,
    batch_size=64,
    shuffle=True
)

test_loader = DataLoader(
    test_data,
    batch_size=1000,
    shuffle=False
)

print("æˆåŠŸåŠ è½½æ•°æ®é›†:")
print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(train_data)}")
print(f"æµ‹è¯•æ ·æœ¬æ•°: {len(test_data)}")

# æŸ¥çœ‹ä¸€ä¸ªæ ·æœ¬
sample, label = train_data[0]
print(f"æ ·æœ¬å½¢çŠ¶: {sample.shape}, æ ‡ç­¾: {label}")

# 3. ç¥ç»ç½‘ç»œæ¨¡å‹å®šä¹‰
# =====================================================================
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        # å®šä¹‰å…¨è¿æ¥å±‚ (Linear)
        # 28 * 28=784åƒç´ è¾“å…¥ -> 512ä¸ªç¥ç»å…ƒ -> 256ä¸ªç¥ç»å…ƒ -> 10ä¸ªè¾“å‡º (å¯¹åº”0-9æ•°å­—)
        self.fc1 = nn.Linear(784, 512)
        self.fc2 = nn.Linear(512, 256)
        self.fc3 = nn.Linear(256, 10)
        # æ·»åŠ dropoutå±‚é˜²æ­¢è¿‡æ‹Ÿåˆ (æŒ‰25%æ¦‚ç‡éšæœºä¸¢å¼ƒç¥ç»å…ƒ)
        self.dropout = nn.Dropout(0.25)

    def forward(self, x):
        # å°†å›¾åƒæ•°æ®å±•å¹³ä¸ºä¸€ç»´å‘é‡ (batch_size, 1, 28, 28) -> (batch_size, 784)
        x = x.view(-1, 28 * 28)
        
        # ç¬¬ä¸€å±‚ï¼šå…¨è¿æ¥ + ReLUæ¿€æ´»å‡½æ•° + Dropout
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        
        # ç¬¬äºŒå±‚ï¼šå…¨è¿æ¥ + ReLUæ¿€æ´»å‡½æ•°
        x = F.relu(self.fc2(x))
        
        # è¾“å‡ºå±‚ï¼šå…¨è¿æ¥ + LogSoftmax (æ›´é€‚åˆä¸NLLLossé…åˆ)
        x = self.fc3(x)
        return F.log_softmax(x, dim=1)

# 4. æ¨¡å‹è®­ç»ƒè®¾ç½®
# =====================================================================
# é€‰æ‹©è®¾å¤‡ (ä¼˜å…ˆä½¿ç”¨GPUåŠ é€Ÿ)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"\nä½¿ç”¨è®¾å¤‡: {device}")
if str(device) == "cpu":
    print("æç¤ºï¼šä½¿ç”¨GPUå¯ä»¥å¤§å¤§åŠ å¿«è®­ç»ƒé€Ÿåº¦ã€‚å¦‚æœä½ æœ‰NVIDIAæ˜¾å¡ï¼Œè¯·ç¡®ä¿å®‰è£…äº†CUDAé©±åŠ¨ç¨‹åºã€‚")

# å®ä¾‹åŒ–æ¨¡å‹å¹¶ç§»åˆ°è®¾å¤‡ä¸Š
model = Net().to(device)

# æ‰“å°æ¨¡å‹æ‘˜è¦
print("\næ¨¡å‹æ¶æ„:")
print(model)

# å®šä¹‰ä¼˜åŒ–å™¨ (Adamä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡0.001)
optimizer = optim.Adam(model.parameters(), lr=0.001)

# å­¦ä¹ ç‡è°ƒåº¦å™¨ (æ¯10ä¸ªepochå­¦ä¹ ç‡ä¹˜ä»¥0.1)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)

# 5. è®­ç»ƒå¾ªç¯
# =====================================================================
epochs = 10
train_losses = []  # è®°å½•æ¯ä¸ªepochçš„å¹³å‡æŸå¤±
train_accuracies = []  # è®°å½•æ¯ä¸ªepochçš„è®­ç»ƒå‡†ç¡®ç‡
test_losses = []  # è®°å½•æ¯ä¸ªepochçš„æµ‹è¯•æŸå¤±
test_accuracies = []  # è®°å½•æ¯ä¸ªepochçš„æµ‹è¯•å‡†ç¡®ç‡

for epoch in range(1, epochs + 1):
    model.train()  # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼ (å¯ç”¨dropout)
    train_loss = 0
    correct = 0
    total = 0
    
    # è®­ç»ƒä¸€ä¸ªepoch
    for batch_idx, (data, target) in enumerate(train_loader):
        # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
        data, target = data.to(device), target.to(device)
        
        # æ¢¯åº¦å½’é›¶ (é‡è¦ï¼å¦åˆ™æ¢¯åº¦ä¼šç´¯ç§¯)
        optimizer.zero_grad()
        
        # å‰å‘ä¼ æ’­
        output = model(data)
        
        # è®¡ç®—æŸå¤± (ä½¿ç”¨è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±)
        loss = F.nll_loss(output, target)
        
        # åå‘ä¼ æ’­
        loss.backward()
        
        # å‚æ•°æ›´æ–°
        optimizer.step()
        
        # è®°å½•ç»Ÿè®¡ä¿¡æ¯
        train_loss += loss.item() * data.size(0)  # ä¹˜ä»¥batch sizeä»¥è®¡ç®—æ€»æŸå¤±
        _, predicted = output.max(1)
        total += target.size(0)
        correct += predicted.eq(target).sum().item()
        
        # æ¯100ä¸ªbatchæ‰“å°ä¸€æ¬¡è¿›åº¦
        if batch_idx % 100 == 0:
            current_lr = optimizer.param_groups[0]['lr']
            progress = 100. * batch_idx / len(train_loader)
            print(f'Epoch: {epoch}/{epochs} [{batch_idx}/{len(train_loader)}]'
                  f' ({progress:.0f}%) | '
                  f'Loss: {loss.item():.4f} | LR: {current_lr:.6f}')
    
    # æ›´æ–°å­¦ä¹ ç‡ (æ¯ä¸ªepochç»“æŸåè°ƒç”¨)
    scheduler.step()
    
    # è®¡ç®—è®­ç»ƒé›†çš„å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡
    train_loss /= len(train_loader.dataset)  # å¹³å‡æŸå¤±
    train_accuracy = 100. * correct / total
    train_losses.append(train_loss)
    train_accuracies.append(train_accuracy)
    
    # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹
    model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ (ç¦ç”¨dropout)
    test_loss = 0
    correct = 0
    total = 0
    
    with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ŒèŠ‚çœå†…å­˜å’Œè®¡ç®—èµ„æº
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sumå°†æŸå¤±ç´¯åŠ 
            _, predicted = output.max(1)
            total += target.size(0)
            correct += predicted.eq(target).sum().item()
    
    # è®¡ç®—æµ‹è¯•é›†çš„å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡
    test_loss /= total  # å¹³å‡æŸå¤±
    test_accuracy = 100. * correct / total
    test_losses.append(test_loss)
    test_accuracies.append(test_accuracy)
    
    # æ‰“å°æ¯ä¸ªepochçš„æœ€ç»ˆç»“æœ
    print(f'\nEpoch {epoch} å®Œæˆ: ')
    print(f'è®­ç»ƒæŸå¤±: {train_loss:.6f}, è®­ç»ƒå‡†ç¡®ç‡: {train_accuracy:.2f}% | '
          f'æµ‹è¯•æŸå¤±: {test_loss:.6f}, æµ‹è¯•å‡†ç¡®ç‡: {test_accuracy:.2f}%\n')

# ä¿å­˜æœ€ç»ˆæ¨¡å‹
os.makedirs('./models', exist_ok=True)
model_path = './models/first_ai_model.pth'
torch.save(model.state_dict(), model_path)
print(f"æ¨¡å‹å·²ä¿å­˜ä¸º '{model_path}'")

# 6. ç»“æœå¯è§†åŒ–
# =====================================================================
plt.figure(figsize=(12, 5))

# æŸå¤±æ›²çº¿
plt.subplot(1, 2, 1)
plt.plot(train_losses, 'o-', label='è®­ç»ƒæŸå¤±')
plt.plot(test_losses, 'o-', label='æµ‹è¯•æŸå¤±')
plt.title('è®­ç»ƒå’Œæµ‹è¯•æŸå¤±')
plt.xlabel('Epoch')
plt.ylabel('æŸå¤±å€¼')
plt.legend()
plt.grid(True)

# å‡†ç¡®ç‡æ›²çº¿
plt.subplot(1, 2, 2)
plt.plot(train_accuracies, 'o-', label='è®­ç»ƒå‡†ç¡®ç‡')
plt.plot(test_accuracies, 'o-', label='æµ‹è¯•å‡†ç¡®ç‡')
plt.title('è®­ç»ƒå’Œæµ‹è¯•å‡†ç¡®ç‡')
plt.xlabel('Epoch')
plt.ylabel('å‡†ç¡®ç‡ (%)')
plt.legend()
plt.grid(True)

plt.tight_layout()
plot_path = './training_results.png'
plt.savefig(plot_path)
print(f"è®­ç»ƒç»“æœå›¾è¡¨å·²ä¿å­˜ä¸º '{plot_path}'")
plt.show()

# æŸ¥çœ‹å­¦ä¹ ç‡å˜åŒ–
final_lr = optimizer.param_groups[0]['lr']
print(f'\næœ€ç»ˆå­¦ä¹ ç‡: {final_lr:.8f}')

print("\nè®­ç»ƒå®Œæˆï¼æ‚¨å·²ç»æˆåŠŸè®­ç»ƒäº†æ‚¨çš„ç¬¬ä¸€ä¸ªäººå·¥æ™ºèƒ½æ¨¡å‹ï¼ğŸ‰")